{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Specialized Agents in Parallel with the OpenAI Agents SDK\n",
    "\n",
    "Why would you want to do this?\n",
    "In many production workflows you must answer several independent questions about the same piece of content.\n",
    "Doing those analyses one-by-one increases latency and can increase total cost if any step fails and forces a retry.\n",
    "By \"fanning out\" multiple specialized agents at the same time and then \"fanning in\" their outputs to a final “meta” agent, you're able to reduce this latency.\n",
    "\n",
    "This notebook present a toy example that you likely wouldn't parallelize in the real world, but that shows:\n",
    "1. How to define several focused agents with the OpenAI Agents SDK.\n",
    "2. How to execute them concurrently using either Python [asyncio](https://docs.python.org/3/library/asyncio.html) for lower latency, lightweight parallelization or directly through the [Agents SDK](https://openai.github.io/openai-agents-python/tools/#agents-as-tools) for ease of management and dynamic tool call planning.\n",
    "3. How to gather their individual outputs and feed them into a downstream meta-agent that produces the final, user-ready answer.\n",
    "4. A simple timeline visualization so you can see the latency benefit of parallelization.\n",
    "\n",
    "This same pattern can be adapted to real world scenarios such as customer-support triage, content moderation, or other scenarios where you might want to run multiple independent analyses on an input and merge them into a single outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-agents in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.17)\n",
      "Requirement already satisfied: asyncio in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.4.3)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: nest_asyncio in /home/codespace/.local/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai-agents) (1.7.3)\n",
      "Requirement already satisfied: mcp<2,>=1.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai-agents) (1.9.4)\n",
      "Requirement already satisfied: openai>=1.81.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai-agents) (1.86.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai-agents) (2.11.5)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai-agents) (2.32.3)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai-agents) (2.32.4.20250611)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from openai-agents) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/codespace/.local/lib/python3.12/site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/codespace/.local/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (0.4.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/codespace/.local/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (2.3.6)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (0.47.0)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from mcp<2,>=1.8.0->openai-agents) (0.34.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=1.81.0->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=1.81.0->openai-agents) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai>=1.81.0->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=1.81.0->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.0->openai-agents) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.27->mcp<2,>=1.8.0->openai-agents) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.8.0->openai-agents) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.8.0->openai-agents) (1.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from uvicorn>=0.23.1->mcp<2,>=1.8.0->openai-agents) (8.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai-agents asyncio matplotlib nest_asyncio\n",
    "\n",
    "import time\n",
    "\n",
    "import asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio\n",
    "\n",
    "from agents import Agent, Runner\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define your Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent focusing on product features\n",
    "features_agent = Agent(\n",
    "    name=\"FeaturesAgent\",\n",
    "    instructions=\"Extract the key product features from the review.\"\n",
    ")\n",
    "\n",
    "# Agent focusing on pros & cons\n",
    "pros_cons_agent = Agent(\n",
    "    name=\"ProsConsAgent\",\n",
    "    instructions=\"List the pros and cons mentioned in the review.\"\n",
    ")\n",
    "\n",
    "# Agent focusing on sentiment analysis\n",
    "sentiment_agent = Agent(\n",
    "    name=\"SentimentAgent\",\n",
    "    instructions=\"Summarize the overall user sentiment from the review.\"\n",
    ")\n",
    "\n",
    "# Agent focusing on recommendation summary\n",
    "recommend_agent = Agent(\n",
    "    name=\"RecommendAgent\",\n",
    "    instructions=\"State whether you would recommend this product and why.\"\n",
    ")\n",
    "\n",
    "parallel_agents = [\n",
    "    features_agent,\n",
    "    pros_cons_agent,\n",
    "    sentiment_agent,\n",
    "    recommend_agent\n",
    "]\n",
    "\n",
    "# Meta-agent to combine outputs\n",
    "meta_agent = Agent(\n",
    "    name=\"MetaAgent\",\n",
    "    instructions=\"You are given multiple summaries labeled with Features, ProsCons, Sentiment, and a Recommendation.\"\n",
    "    \" Combine them into a concise executive summary of the product review with a 1-5 star rating for each summary area.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts, ends = [], []\n",
    "async def run_agent(agent, review_text: str):\n",
    "    agent_name = agent.name\n",
    "\n",
    "    start = time.time()\n",
    "    starts.append((agent_name, start))\n",
    "\n",
    "    result = await Runner.run(agent, review_text)\n",
    "\n",
    "    end = time.time()\n",
    "    ends.append((agent_name, end))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create function for parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agents(review_text: str):\n",
    "    responses = await asyncio.gather(\n",
    "        *(run_agent(agent, review_text) for agent in parallel_agents)\n",
    "    )\n",
    "\n",
    "    labeled_summaries = [\n",
    "        f\"### {resp.last_agent.name}\\n{resp.final_output}\"\n",
    "        for resp in responses\n",
    "    ]\n",
    "\n",
    "    collected_summaries = \"\\n\".join(labeled_summaries)\n",
    "    final_summary = await run_agent(meta_agent, collected_summaries)\n",
    "\n",
    "\n",
    "    print('Final summary:', final_summary.final_output)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}. (request_id: req_b7bc448fa1f30ded935d2110dcd19c3e)\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      4\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33msk-...\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# <-- Replace with your actual API key\u001b[39;00m\n\u001b[32m      6\u001b[39m review_text = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mI recently upgraded to the AuroraSound X2 wireless noise-cancelling headphones, and after two weeks of daily use I have quite a bit to share. First off, the design feels premium without being flashy: the matte‐finish ear cups are softly padded and rotate smoothly for storage, while the headband’s memory‐foam cushion barely presses on my temples even after marathon work calls. Connectivity is seamless—pairing with my laptop and phone took under five seconds each time, and the Bluetooth 5.2 link held rock-solid through walls and down the hallway.\u001b[39m\n\u001b[32m      8\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33mThat said, it isn’t perfect. For one, the carrying case is a bit bulky, so it doesn’t slip easily into a slim bag. And while the touch interface is mostly reliable, I occasionally trigger a pause when trying to adjust the cup position. The headphones also come in only two colorways—black or white—which feels limiting given the premium price point.\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_timeline\u001b[39m(starts, ends):\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# Plot the timeline of the agents\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# normalize times to zero\u001b[39;00m\n\u001b[32m     22\u001b[39m     base = \u001b[38;5;28mmin\u001b[39m(t \u001b[38;5;28;01mfor\u001b[39;00m _, t \u001b[38;5;129;01min\u001b[39;00m starts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrun_agents\u001b[39m\u001b[34m(review_text)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_agents\u001b[39m(review_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     responses = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m      3\u001b[39m         *(run_agent(agent, review_text) \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m parallel_agents)\n\u001b[32m      4\u001b[39m     )\n\u001b[32m      6\u001b[39m     labeled_summaries = [\n\u001b[32m      7\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m### \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.last_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresp.final_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m responses\n\u001b[32m      9\u001b[39m     ]\n\u001b[32m     11\u001b[39m     collected_summaries = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(labeled_summaries)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(agent, review_text)\u001b[39m\n\u001b[32m      5\u001b[39m start = time.time()\n\u001b[32m      6\u001b[39m starts.append((agent_name, start))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(agent, review_text)\n\u001b[32m     10\u001b[39m end = time.time()\n\u001b[32m     11\u001b[39m ends.append((agent_name, end))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/agents/run.py:219\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    214\u001b[39m logger.debug(\n\u001b[32m    215\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    221\u001b[39m             starting_agent,\n\u001b[32m    222\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    223\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    224\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    225\u001b[39m             context_wrapper,\n\u001b[32m    226\u001b[39m         ),\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    228\u001b[39m             agent=current_agent,\n\u001b[32m    229\u001b[39m             all_tools=all_tools,\n\u001b[32m    230\u001b[39m             original_input=original_input,\n\u001b[32m    231\u001b[39m             generated_items=generated_items,\n\u001b[32m    232\u001b[39m             hooks=hooks,\n\u001b[32m    233\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    234\u001b[39m             run_config=run_config,\n\u001b[32m    235\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    236\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    237\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    238\u001b[39m         ),\n\u001b[32m    239\u001b[39m     )\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    241\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    242\u001b[39m         agent=current_agent,\n\u001b[32m    243\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    252\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/agents/run.py:787\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    785\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    788\u001b[39m     agent,\n\u001b[32m    789\u001b[39m     system_prompt,\n\u001b[32m    790\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    791\u001b[39m     output_schema,\n\u001b[32m    792\u001b[39m     all_tools,\n\u001b[32m    793\u001b[39m     handoffs,\n\u001b[32m    794\u001b[39m     context_wrapper,\n\u001b[32m    795\u001b[39m     run_config,\n\u001b[32m    796\u001b[39m     tool_use_tracker,\n\u001b[32m    797\u001b[39m     previous_response_id,\n\u001b[32m    798\u001b[39m )\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    801\u001b[39m     agent=agent,\n\u001b[32m    802\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    811\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    812\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/agents/run.py:946\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    943\u001b[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    944\u001b[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m model.get_response(\n\u001b[32m    947\u001b[39m     system_instructions=system_prompt,\n\u001b[32m    948\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    949\u001b[39m     model_settings=model_settings,\n\u001b[32m    950\u001b[39m     tools=all_tools,\n\u001b[32m    951\u001b[39m     output_schema=output_schema,\n\u001b[32m    952\u001b[39m     handoffs=handoffs,\n\u001b[32m    953\u001b[39m     tracing=get_model_tracing_impl(\n\u001b[32m    954\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    955\u001b[39m     ),\n\u001b[32m    956\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    957\u001b[39m )\n\u001b[32m    959\u001b[39m context_wrapper.usage.add(new_response.usage)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/agents/models/openai_responses.py:80\u001b[39m, in \u001b[36mOpenAIResponsesModel.get_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m response_span(disabled=tracing.is_disabled()) \u001b[38;5;28;01mas\u001b[39;00m span_response:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m     81\u001b[39m             system_instructions,\n\u001b[32m     82\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m     83\u001b[39m             model_settings,\n\u001b[32m     84\u001b[39m             tools,\n\u001b[32m     85\u001b[39m             output_schema,\n\u001b[32m     86\u001b[39m             handoffs,\n\u001b[32m     87\u001b[39m             previous_response_id,\n\u001b[32m     88\u001b[39m             stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001b[32m     92\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLLM responded\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/agents/models/openai_responses.py:248\u001b[39m, in \u001b[36mOpenAIResponsesModel._fetch_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    238\u001b[39m     logger.debug(\n\u001b[32m    239\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling LLM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(list_input,\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrevious response id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprevious_response_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.responses.create(\n\u001b[32m    249\u001b[39m     previous_response_id=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(previous_response_id),\n\u001b[32m    250\u001b[39m     instructions=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(system_instructions),\n\u001b[32m    251\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    252\u001b[39m     \u001b[38;5;28minput\u001b[39m=list_input,\n\u001b[32m    253\u001b[39m     include=converted_tools.includes,\n\u001b[32m    254\u001b[39m     tools=converted_tools.tools,\n\u001b[32m    255\u001b[39m     temperature=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.temperature),\n\u001b[32m    256\u001b[39m     top_p=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.top_p),\n\u001b[32m    257\u001b[39m     truncation=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.truncation),\n\u001b[32m    258\u001b[39m     max_output_tokens=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001b[32m    259\u001b[39m     tool_choice=tool_choice,\n\u001b[32m    260\u001b[39m     parallel_tool_calls=parallel_tool_calls,\n\u001b[32m    261\u001b[39m     stream=stream,\n\u001b[32m    262\u001b[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})},\n\u001b[32m    263\u001b[39m     extra_query=model_settings.extra_query,\n\u001b[32m    264\u001b[39m     extra_body=model_settings.extra_body,\n\u001b[32m    265\u001b[39m     text=response_format,\n\u001b[32m    266\u001b[39m     store=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.store),\n\u001b[32m    267\u001b[39m     reasoning=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.reasoning),\n\u001b[32m    268\u001b[39m     metadata=\u001b[38;5;28mself\u001b[39m._non_null_or_not_given(model_settings.metadata),\n\u001b[32m    269\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/resources/responses/responses.py:1898\u001b[39m, in \u001b[36mAsyncResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1867\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1868\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1869\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1896\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1897\u001b[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1899\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/responses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1900\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   1901\u001b[39m             {\n\u001b[32m   1902\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1903\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1904\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbackground\u001b[39m\u001b[33m\"\u001b[39m: background,\n\u001b[32m   1905\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m: include,\n\u001b[32m   1906\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions,\n\u001b[32m   1907\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_output_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_output_tokens,\n\u001b[32m   1908\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1909\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1910\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprevious_response_id\u001b[39m\u001b[33m\"\u001b[39m: previous_response_id,\n\u001b[32m   1911\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m: reasoning,\n\u001b[32m   1912\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1913\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1914\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1915\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1916\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   1917\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1918\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1919\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1920\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtruncation\u001b[39m\u001b[33m\"\u001b[39m: truncation,\n\u001b[32m   1921\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1922\u001b[39m             },\n\u001b[32m   1923\u001b[39m             response_create_params.ResponseCreateParamsStreaming\n\u001b[32m   1924\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1925\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001b[32m   1926\u001b[39m         ),\n\u001b[32m   1927\u001b[39m         options=make_request_options(\n\u001b[32m   1928\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1929\u001b[39m         ),\n\u001b[32m   1930\u001b[39m         cast_to=Response,\n\u001b[32m   1931\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1932\u001b[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001b[32m   1933\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1748\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1734\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1735\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1736\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1743\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1744\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1745\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1746\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1747\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1748\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/openai/_base_client.py:1555\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1552\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1554\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1555\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1557\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}. (request_id: req_00125b6a496946f52c48bfbebd59461f)\n",
      "Error getting response: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}. (request_id: req_ad4d15ee3f31da56f60e8c61f9cc9479)\n",
      "Error getting response: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}. (request_id: req_c506139e530b10f5513bf8e46fd1ae36)\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: sk-.... You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # <-- Replace with your actual API key\n",
    "\n",
    "review_text = \"\"\"\n",
    "I recently upgraded to the AuroraSound X2 wireless noise-cancelling headphones, and after two weeks of daily use I have quite a bit to share. First off, the design feels premium without being flashy: the matte‐finish ear cups are softly padded and rotate smoothly for storage, while the headband’s memory‐foam cushion barely presses on my temples even after marathon work calls. Connectivity is seamless—pairing with my laptop and phone took under five seconds each time, and the Bluetooth 5.2 link held rock-solid through walls and down the hallway.\n",
    "\n",
    "The noise-cancelling performance is genuinely impressive. In a busy café with music and chatter swirling around, flipping on ANC immediately quiets low-level ambient hums, and it even attenuates sudden noises—like the barista’s milk frother—without sounding distorted. The “Transparency” mode is equally well‐tuned: voices come through clearly, but the world outside isn’t overwhelmingly loud. Audio quality in standard mode is rich and balanced, with tight bass, clear mids, and a hint of sparkle in the highs. There’s also a dedicated EQ app, where you can toggle between “Podcast,” “Bass Boost,” and “Concert Hall” presets or craft your own curve.\n",
    "\n",
    "On the control front, intuitive touch panels let you play/pause, skip tracks, and adjust volume with a simple swipe or tap. One neat trick: holding down on the right ear cup invokes your phone’s voice assistant. Battery life lives up to the hype, too—over 30 hours with ANC on, and the quick‐charge feature delivers 2 hours of playtime from just a 10-minute top-up.\n",
    "\n",
    "That said, it isn’t perfect. For one, the carrying case is a bit bulky, so it doesn’t slip easily into a slim bag. And while the touch interface is mostly reliable, I occasionally trigger a pause when trying to adjust the cup position. The headphones also come in only two colorways—black or white—which feels limiting given the premium price point.\n",
    "\"\"\"\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(run_agents(review_text))\n",
    "\n",
    "def plot_timeline(starts, ends):\n",
    "\n",
    "    # Plot the timeline of the agents\n",
    "    # normalize times to zero\n",
    "    base = min(t for _, t in starts)\n",
    "    labels = [n for n, _ in starts]\n",
    "    start_offsets = [t - base for _, t in starts]\n",
    "    lengths = [ends[i][1] - starts[i][1] for i in range(len(starts))]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.barh(labels, lengths, left=start_offsets)\n",
    "    plt.xlabel(\"Seconds since kickoff\")\n",
    "    plt.title(\"Agent Execution Timeline\")\n",
    "    plt.show()\n",
    "\n",
    "plot_timeline(starts, ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agents can also be parallelized directly through the SDK via the \"agent as tool\" route, adding convenience and the assistance of the planner dynamically deciding which tools to call at the expense of higher latency. This latency comes both from the additional planning API call up front, along with the higher overhead and context from the tool call objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final summary: **Executive Summary: AuroraSound X2 Wireless Noise-Cancelling Headphones**\n",
      "\n",
      "**Features (⭐️⭐️⭐️⭐️⭐️ 5/5):** The headphones boast a premium, matte-finish design with comfortable memory-foam cushioning. They offer seamless Bluetooth 5.2 connectivity, impressive noise-cancelling capabilities, and a well-tuned \"Transparency\" mode. The audio quality is rich and balanced, with customizable sound options via a dedicated EQ app. Additional features include intuitive touch controls and excellent battery life paired with a quick-charge option.\n",
      "\n",
      "**Pros and Cons (⭐️⭐️⭐️⭐️ 4/5):** \n",
      "- **Pros:** Premium design, comfortable fit, seamless connectivity, effective noise-cancelling, clear voice input in \"Transparency\" mode, customizable audio, intuitive controls, long battery life.\n",
      "- **Cons:** Bulky carrying case, occasional touch control sensitivity issues, limited color options.\n",
      "\n",
      "**Sentiment (⭐️⭐️⭐️⭐️ 4/5):** The overall sentiment is highly positive, with appreciation for the design, comfort, connectivity, noise-cancelling effectiveness, and audio quality. Minor drawbacks are noted but do not outweigh the benefits.\n",
      "\n",
      "**Recommendation (⭐️⭐️⭐️⭐️ 4/5):** Highly recommended for those seeking premium noise-cancelling headphones with versatile features and excellent audio performance. The minor drawbacks are outweighed by the comprehensive suite of high-quality features.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents import ModelSettings\n",
    "\n",
    "\n",
    "meta_agent_parallel_tools = Agent(\n",
    "    name=\"MetaAgent\",\n",
    "    instructions=\"You are given multiple summaries labeled with Features, ProsCons, Sentiment, and a Recommendation.\"\n",
    "    \" Combine them into a concise executive summary of the product review with a 1-5 star rating for each summary area.\",\n",
    "   model_settings=ModelSettings(\n",
    "       parallel_tool_calls=True\n",
    "   ),\n",
    "    tools=[\n",
    "        features_agent.as_tool(\n",
    "            tool_name=\"features\",\n",
    "            tool_description=\"Extract the key product features from the review.\",\n",
    "        ),\n",
    "        pros_cons_agent.as_tool(\n",
    "            tool_name=\"pros_cons\",\n",
    "            tool_description=\"List the pros and cons mentioned in the review.\",\n",
    "        ),\n",
    "        sentiment_agent.as_tool(\n",
    "            tool_name=\"sentiment\",\n",
    "            tool_description=\"Summarize the overall user sentiment from the review.\",\n",
    "        ),\n",
    "        recommend_agent.as_tool(\n",
    "            tool_name=\"recommend\",\n",
    "            tool_description=\"State whether you would recommend this product and why.\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "starts, ends = [], []\n",
    "result = await run_agent(meta_agent_parallel_tools, review_text)\n",
    "\n",
    "print('Final summary:', result.final_output)\n",
    "\n",
    "plot_timeline(starts, ends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "From the above, we can see two different patterns for parallelizing agents. Ultimately, the approach you use will depend on the balance you want between:\n",
    "\n",
    "1. Convenience vs. customization\n",
    "    * If you prefer convenience, the agent as tool route is the way to go. If you want to customize how agents fan in and out across multiple layers, building a graph with `asyncio.gather` might make more sense\n",
    "1. Planning vs. determinism\n",
    "    * If you want your planner (in this case the meta agent) to dynamically decide which tools to call and the order, you should use agents as tools whereas `asyncio.gather` makes more sense if you want a deterministic order.\n",
    "1. Latency sensitivity\n",
    "    * If you're highly sensitive to latency, you may want to use `asyncio` to avoid the additional upfront cost of planning the parallel tools and the overhead of tool outputs and longer context windows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
